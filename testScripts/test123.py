#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¡Œé¢éŸ³é¢‘å®æ—¶VADæµ‹è¯•è„šæœ¬ (æ™ºèƒ½é€‚é…æœ€ç»ˆç‰ˆ)
- è‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨è®¾å¤‡æ”¯æŒçš„æ­£ç¡®éŸ³é¢‘æ ¼å¼(format)å’Œå£°é“æ•°(channels)ã€‚
- æ­£ç¡®åœ°å°†æ•è·çš„éŸ³é¢‘æ•°æ®æ ‡å‡†åŒ–ä¸º float32 æ ¼å¼ã€‚
- æ­£ç¡®åœ°å¤„ç†ç«‹ä½“å£°åˆ°å•å£°é“çš„è½¬æ¢ã€‚
- ä½¿ç”¨ librosa è¿›è¡Œé«˜è´¨é‡é‡é‡‡æ ·ã€‚
"""

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import numpy as np
import time
from datetime import datetime
from pathlib import Path
from collections import deque

try:
    import pyaudiowpatch as pyaudio
except ImportError:
    print("[ERROR] è¯·å…ˆå®‰è£…PyAudioWPatch: pip install pyaudiowpatch")
    sys.exit(1)

try:
    import librosa
except ImportError:
    print("[ERROR] è¯·å…ˆå®‰è£…librosa: pip install librosa")
    sys.exit(1)

from src.core.onnx_vad import SileroVADONNX

# --- NEW: ç”¨äºæ•°æ®æ ‡å‡†åŒ–çš„è¾…åŠ©å‡½æ•° ---
def get_format_info(p, audio_format):
    """æ ¹æ®PyAudioçš„æ ¼å¼å¸¸é‡ï¼Œè¿”å›Numpyæ•°æ®ç±»å‹å’Œæ ‡å‡†åŒ–å› å­"""
    if audio_format == pyaudio.paFloat32:
        return np.float32, 1.0
    elif audio_format == pyaudio.paInt32:
        return np.int32, 2**31 - 1
    elif audio_format == pyaudio.paInt24:
        # paInt24 is technically 3 bytes, but often read into a 4-byte int
        # The max value is 2^23 - 1
        return np.int32, 2**23 - 1
    elif audio_format == pyaudio.paInt16:
        return np.int16, 2**15 - 1
    elif audio_format == pyaudio.paInt8 or audio_format == pyaudio.paUInt8:
        return np.int8, 2**7 - 1
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„éŸ³é¢‘æ ¼å¼: {audio_format}")


class DesktopAudioVADTester:
    VAD_TARGET_SAMPLE_RATE = 16000
    VAD_WINDOW_SIZE = 1536

    def __init__(self, vad_threshold=0.5, debug_mode=False):
        self.vad = SileroVADONNX()
        self.threshold = vad_threshold
        self.debug_mode = debug_mode
        self._audio_buffer = np.array([], dtype=np.float32)
        # ... (å…¶ä»–åˆå§‹åŒ–å˜é‡ä¿æŒä¸å˜)
        self.speech_start_time = 0; self.is_currently_speaking = False
        self.silence_frames_after_speech = 0; self.silence_trigger_threshold = 10
        self.speech_buffer = deque(maxlen=5); self.start_time = None; self.running = False
        self.debug_audio_buffer = []; self.debug_dir = Path("debug_audio")
        self.debug_dir.mkdir(exist_ok=True); self.debug_session_id = datetime.now().strftime("%Y%m%d_%H%M%S")

    def process_audio_stream(self, audio_chunk_float32, original_sample_rate):
        """æ¥æ”¶å·²æ ‡å‡†åŒ–ä¸ºfloat32çš„å•å£°é“éŸ³é¢‘æµ"""
        resampled_audio = librosa.resample(
            y=audio_chunk_float32, 
            orig_sr=original_sample_rate, 
            target_sr=self.VAD_TARGET_SAMPLE_RATE
        )
        self._audio_buffer = np.concatenate([self._audio_buffer, resampled_audio])

        while len(self._audio_buffer) >= self.VAD_WINDOW_SIZE:
            vad_chunk = self._audio_buffer[:self.VAD_WINDOW_SIZE]
            self._audio_buffer = self._audio_buffer[self.VAD_WINDOW_SIZE:]

            peak_volume = np.max(np.abs(vad_chunk))
            prob = self.vad(vad_chunk)
            
            print(f"[VAD Chunk] Peak: {peak_volume:.4f}, VAD Prob: {prob:.3f}")

            self.update_speech_state(prob >= self.threshold, prob)
            
            if self.debug_mode:
                self.debug_audio_buffer.extend(vad_chunk)

    def update_speech_state(self, is_speech, probability):
        # ... (æ­¤æ–¹æ³•ä¿æŒä¸å˜)
        self.speech_buffer.append(is_speech)
        if not self.is_currently_speaking and sum(self.speech_buffer) >= 3:
            self.is_currently_speaking = True; self.speech_start_time = time.time(); self.silence_frames_after_speech = 0
            print(f"ğŸ¤ [è¯­éŸ³è¿›å…¥] æ£€æµ‹åˆ°è¯­éŸ³å¼€å§‹! æ¦‚ç‡: {probability:.3f}")
        elif self.is_currently_speaking and not is_speech:
            self.silence_frames_after_speech += 1
            if self.silence_frames_after_speech >= self.silence_trigger_threshold:
                speech_duration = time.time() - self.speech_start_time
                print(f"ğŸ”‡ [è¯­éŸ³é€€å‡º] è¯­éŸ³ç»“æŸ! æŒç»­æ—¶é—´: {speech_duration:.2f}ç§’")
                self.is_currently_speaking = False; self.speech_buffer.clear()
        elif self.is_currently_speaking and is_speech:
            self.silence_frames_after_speech = 0
            
    def start_realtime_testing(self, duration=None):
        print("[INFO] æ­£åœ¨åˆå§‹åŒ–æ¡Œé¢éŸ³é¢‘ç›‘å¬...")
        
        p = pyaudio.PyAudio()
        try:
            device_info = p.get_default_wasapi_loopback()
            rate = int(device_info["defaultSampleRate"])
            channels = device_info["maxInputChannels"]
            
            # --- å…³é”®: æ™ºèƒ½æ ¼å¼å‘ç° ---
            # æˆ‘ä»¬ä¼˜å…ˆå°è¯•float32ï¼Œå¦‚æœä¸æ”¯æŒï¼Œåˆ™å°è¯•int16ï¼Œè¿™æ˜¯æœ€å¸¸è§çš„ç»„åˆ
            supported_formats = [pyaudio.paFloat32, pyaudio.paInt16, pyaudio.paInt32, pyaudio.paInt24]
            audio_format = None
            for f in supported_formats:
                if p.is_format_supported(rate, input_device=device_info['index'], input_channels=channels, input_format=f):
                    audio_format = f
                    break
            
            if not audio_format:
                raise RuntimeError("è®¾å¤‡ä¸æ”¯æŒä»»ä½•å¯ç”¨çš„éŸ³é¢‘æ ¼å¼ (Float32, Int16, Int32, Int24)")

            numpy_dtype, norm_factor = get_format_info(p, audio_format)
            
            print(f"[OK] ä½¿ç”¨è®¾å¤‡: {device_info['name']}")
            print(f"[OK] åŠ¨æ€å‚æ•°: é‡‡æ ·ç‡={rate}Hz, å£°é“={channels}, æ ¼å¼={audio_format} (Numpy: {numpy_dtype.__name__})")
            print(f"[OK] VADé˜ˆå€¼: {self.threshold}")
            print("\n[INFO] å¼€å§‹ç›‘å¬... (æŒ‰ Ctrl+C åœæ­¢)")
            print("-" * 60)
            
            self.vad.reset_states()

            stream = p.open(
                format=audio_format,
                channels=channels,
                rate=rate,
                input=True,
                input_device_index=device_info["index"],
            )

            self.running = True
            while self.running:
                if duration and (time.time() - (self.start_time or time.time())) > duration: break
                if not self.start_time: self.start_time = time.time()

                chunk_size = int(rate * 0.1) # æ¯æ¬¡è¯»å–100ms
                data = stream.read(chunk_size, exception_on_overflow=False)
                
                # 1. å­—èŠ‚æµ -> Numpyæ•°ç»„
                audio_np = np.frombuffer(data, dtype=numpy_dtype)
                
                # 2. æ ‡å‡†åŒ– -> Float32
                if audio_format != pyaudio.paFloat32:
                    audio_np = audio_np.astype(np.float32) / norm_factor
                
                # 3. å¤šå£°é“ -> å•å£°é“
                if channels > 1:
                    # å°†å½¢çŠ¶ä» (N*channels,) å˜ä¸º (N, channels)
                    audio_np = audio_np.reshape(-1, channels)
                    # å–å¹³å‡å€¼å˜ä¸ºå•å£°é“
                    audio_np = audio_np.mean(axis=1)

                # 4. å°†å¹²å‡€çš„éŸ³é¢‘é€å…¥å¤„ç†æµæ°´çº¿
                self.process_audio_stream(audio_np, rate)

        except KeyboardInterrupt:
            print("\n\n[INFO] ç”¨æˆ·ä¸­æ–­")
        except Exception as e:
            print(f"\n[ERROR] å‘ç”Ÿè‡´å‘½é”™è¯¯: {e}")
            import traceback; traceback.print_exc()
        finally:
            self.running = False
            if 'stream' in locals() and stream.is_active():
                stream.stop_stream(); stream.close()
            p.terminate()
            print("\n[INFO] æµ‹è¯•ç»“æŸã€‚")

# ... (main å‡½æ•°ä¿æŒä¸å˜)
def main():
    print("=" * 60); print("æ¡Œé¢éŸ³é¢‘å®æ—¶VADæµ‹è¯• (æ™ºèƒ½é€‚é…æœ€ç»ˆç‰ˆ)"); print("=" * 60)
    vad_threshold = float(input("VADé˜ˆå€¼(0.0-1.0, é»˜è®¤0.5): ").strip() or 0.5)
    tester = DesktopAudioVADTester(vad_threshold=vad_threshold)
    tester.start_realtime_testing()

if __name__ == "__main__":
    main()